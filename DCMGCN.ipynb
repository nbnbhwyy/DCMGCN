{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Original Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drug_name.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2074442/3512221424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdrug_original_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drug_name.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drug_name.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"./Data/\")\n",
    "\n",
    "drug_size = 464\n",
    "drug_fin, drug_tran, drug_fin_re = {}, {}, {}\n",
    "def feature_extraction(data_name, drug_size):\n",
    "    with open(data_name,'r') as r:\n",
    "        col=0\n",
    "        for line in r:\n",
    "            line=line.strip('\\n').split('\\t')\n",
    "            col=len(line)-1\n",
    "            break\n",
    "        drug_original_feature=np.zeros((drug_size,col))\n",
    "        r.seek(0)\n",
    "        for line in r:\n",
    "            line=line.strip('\\n').split('\\t')\n",
    "            name=line[0]\n",
    "            if name in drug_fin:\n",
    "                del line[0]\n",
    "                drug_original_feature[drug_fin[name]]=np.array(line)\n",
    "    return drug_original_feature\n",
    "       \n",
    "with open(\"drug_name.txt\",'r') as r:\n",
    "    index=0\n",
    "    for line in r:\n",
    "        line=line.strip('\\n')\n",
    "        drug_fin[line]=index\n",
    "        drug_fin_re[index]=line\n",
    "        index+=1\n",
    "        \n",
    "with open(\"drug_name_708.txt\",'r') as r:\n",
    "    index=0\n",
    "    for line in r:\n",
    "        line=line.strip('\\n')\n",
    "        if line in drug_fin:\n",
    "            drug_tran[index]=drug_fin[line]\n",
    "        index+=1\n",
    "\n",
    "X_atc, X_struct, X_off, X_tar, X_drug_drug, X_drug_disease = None, None, None, None, None, None\n",
    "X_atc = feature_extraction(\"Atc_ori.txt\", drug_size)\n",
    "X_struct = feature_extraction(\"Chemical_ori.txt\", drug_size)\n",
    "X_off = feature_extraction(\"Sider_ori.txt\", drug_size)\n",
    "X_tar = feature_extraction(\"Target_ori.txt\", drug_size)\n",
    "X_drug_drug = feature_extraction(\"Drug_drug_ori.txt\", drug_size)\n",
    "# with open(\"mat_drug_drug.txt\",'r') as r:\n",
    "#     col=0\n",
    "#     for line in r:\n",
    "#         line=line.strip('\\n').split('\\t')\n",
    "#         col=len(line)-1\n",
    "#         break\n",
    "#     temp=np.zeros((drug_size,col))\n",
    "#     r.seek(0)\n",
    "#     for line in r:\n",
    "#         line=line.strip('\\n').split('\\t')\n",
    "#         name=line[0]\n",
    "#         if name in drug_fin:\n",
    "#             del line[0]\n",
    "#             temp[drug_fin[name]]=np.array(line)\n",
    "#     X_drug_drug=temp   \n",
    "with open(\"mat_drug_disease.txt\",'r') as r:\n",
    "    col=0\n",
    "    for line in r:\n",
    "        line=line.strip('\\n').split('\\t')\n",
    "        col=len(line)-1\n",
    "        break\n",
    "    temp=np.zeros((drug_size,col))\n",
    "    r.seek(0)\n",
    "    for line in r:\n",
    "        line=line.strip('\\n').split('\\t')\n",
    "        name=line[0]\n",
    "        if name in drug_fin:\n",
    "            del line[0]\n",
    "            temp[drug_fin[name]]=np.array(line)\n",
    "    X_drug_disease=temp   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Similarity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_target = np.zeros((drug_size, drug_size))\n",
    "Sim_sider = np.zeros((drug_size, drug_size))\n",
    "Sim_atc = np.zeros((drug_size, drug_size))\n",
    "Sim_struct = np.zeros((drug_size, drug_size))\n",
    "Sim_drug_drug = np.zeros((drug_size, drug_size))\n",
    "\n",
    "for index in range(drug_size):\n",
    "    for index_2 in range(drug_size):\n",
    "        if index_2 > index:  \n",
    "            X_struct_index = (sum(X_struct[index])+sum(X_struct[index_2])-sum(abs(X_struct[index]-X_struct[index_2])))/2.0\n",
    "            X_atc_index = (sum(X_atc[index])+sum(X_atc[index_2])-sum(abs(X_atc[index]-X_atc[index_2])))/2.0\n",
    "            X_tar_index = (sum(X_tar[index])+sum(X_tar[index_2])-sum(abs(X_tar[index]-X_tar[index_2])))/2.0\n",
    "            X_off_index = (sum(X_off[index])+sum(X_off[index_2])-sum(abs(X_off[index]-X_off[index_2])))/2.0\n",
    "            X_drug_drug_index = (sum(Sim_drug_drug[index])+Sim_drug_drug(X_off[index_2])-sum(abs(Sim_drug_drug[index]-Sim_drug_drug[index_2])))/2.0\n",
    "\n",
    "            if (sum(X_struct[index])+sum(X_struct[index_2])-X_struct_index)!=0:\n",
    "                 Sim_struct[index][index_2]=X_struct_index/(sum(X_struct[index])+sum(X_struct[index_2])-X_struct_index)  \n",
    "                 Sim_struct[index_2][index]=X_struct_index/(sum(X_struct[index])+sum(X_struct[index_2])-X_struct_index)  \n",
    "            if (sum(X_atc[index])+sum(X_atc[index_2])-X_atc_index)!=0:\n",
    "                    Sim_atc[index][index_2]=X_atc_index/(sum(X_atc[index])+sum(X_atc[index_2])-X_atc_index)  \n",
    "                    Sim_atc[index_2][index]=X_atc_index/(sum(X_atc[index])+sum(X_atc[index_2])-X_atc_index)  \n",
    "            if (sum(X_tar[index])+sum(X_tar[index_2])-X_tar_index)!=0:\n",
    "                    Sim_target[index][index_2]=X_tar_index/(sum(X_tar[index])+sum(X_tar[index_2])-X_tar_index)\n",
    "                    Sim_target[index_2][index]=X_tar_index/(sum(X_tar[index])+sum(X_tar[index_2])-X_tar_index)                   \n",
    "            if (sum(X_off[index])+sum(X_off[index_2])-X_off_index)!=0:\n",
    "                    Sim_sider[index][index_2]=X_off_index/(sum(X_off[index])+sum(X_off[index_2])-X_off_index)\n",
    "                    Sim_sider[index_2][index]=X_off_index/(sum(X_off[index])+sum(X_off[index_2])-X_off_index)\n",
    "            if (sum(X_drug_drug[index])+sum(X_drug_drug[index_2])-X_drug_drug_index)!=0:\n",
    "                    Sim_drug_drug[index][index_2]=X_drug_drug_index/(sum(X_drug_drug[index])+sum(X_drug_drug[index_2])-X_drug_drug_index)\n",
    "                    Sim_drug_drug[index_2][index]=X_drug_drug_index/(sum(X_drug_drug[index])+sum(X_drug_drug[index_2])-X_drug_drug_index)\n",
    "\n",
    "def sim_feature(name,size):\n",
    "    drug_sim_feature=np.zeros((size,size))\n",
    "    with open(name,'r') as r:\n",
    "        line_index=0\n",
    "        for line in r:\n",
    "            line=line.strip('\\n').split(\"\\t\")\n",
    "            for index,value in enumerate(line):\n",
    "                if line_index in drug_tran and index in drug_tran:\n",
    "                    drug_sim_feature[drug_tran[line_index]][drug_tran[index]]=float(value)               \n",
    "            line_index+=1\n",
    "    return drug_sim_feature\n",
    "Sim_drug_disease = sim_feature('Sim_mat_drug_disease.txt', drug_size)\n",
    "#Sim_drug_drug = sim_feature('Sim_mat_drug_drug.txt', drug_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Svd_dim = 30\n",
    "\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_off, full_matrices=True)\n",
    "X_off_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_tar, full_matrices=True)\n",
    "X_tar_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_struct, full_matrices=True)\n",
    "X_struct_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_atc, full_matrices=True)\n",
    "X_atc_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_drug_disease, full_matrices=True)\n",
    "X_drug_disease_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(X_drug_drug, full_matrices=True)\n",
    "X_drug_drug_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "X_original_svd = np.hstack((X_off_svd, X_tar_svd))\n",
    "X_original_svd = np.hstack((X_original_svd, X_struct_svd))\n",
    "X_original_svd = np.hstack((X_original_svd, X_atc_svd))\n",
    "X_original_svd = np.hstack((X_original_svd, X_drug_disease_svd))\n",
    "X_original_svd = np.hstack((X_original_svd, X_drug_drug_svd))\n",
    "X_original_svd = torch.from_numpy(X_original_svd).to(\"cpu\").cuda()\n",
    "\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_drug_disease, full_matrices=True)\n",
    "Sim_drug_disease_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_drug_drug, full_matrices=True)\n",
    "Sim_drug_drug_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_sider, full_matrices=True)\n",
    "Sim_sider_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_target, full_matrices=True)\n",
    "Sim_target_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_atc, full_matrices=True)\n",
    "Sim_atc_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "u_P, s_P, vh_P = np.linalg.svd(Sim_struct, full_matrices=True)\n",
    "Sim_struct_svd = u_P[:,0:Svd_dim].dot(np.sqrt(np.sqrt(np.diag(s_P[:Svd_dim]))))\n",
    "X_similarity_svd = np.hstack((Sim_sider_svd, Sim_target_svd))\n",
    "X_similarity_svd = np.hstack((X_similarity_svd, Sim_struct_svd))\n",
    "X_similarity_svd = np.hstack((X_similarity_svd, Sim_atc_svd))\n",
    "X_similarity_svd = np.hstack((X_similarity_svd, Sim_drug_disease_svd))\n",
    "X_similarity_svd = np.hstack((X_similarity_svd, Sim_drug_drug_svd))\n",
    "X_similarity_svd = torch.from_numpy(X_similarity_svd).to(\"cpu\").cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "y_true=np.zeros((drug_size,drug_size))\n",
    "drug=[]\n",
    "Gold_dict={}\n",
    "with open(\"gold_combination.txt\",'r') as f:\n",
    "        for i in f:\n",
    "            i=i.strip('\\n').split('\\t')\n",
    "            if i[0]!=i[1]:\n",
    "                Gold_dict[i[0]+'_'+i[1]]=1\n",
    "                Gold_dict[i[1]+'_'+i[0]]=1\n",
    "\n",
    "with open(\"drug_name.txt\") as r:\n",
    "    for line in r:\n",
    "        line=line.strip('\\n')\n",
    "        drug.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from scipy import sparse\n",
    "from utils import SparseGraphConvolution\n",
    "\n",
    "class GCNEncoderWithFeatures(nn.Module):\n",
    "    def __init__(self, num_features: int,\n",
    "                 dropout: float = 0.3, bias: bool = False):\n",
    "        super(GCNEncoderWithFeatures, self).__init__()\n",
    "        self.input_dim = num_features\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bias = bias\n",
    "        gcn_hidden1=180\n",
    "        gcn_hidden2=180\n",
    "        GC = SparseGraphConvolution \n",
    "        self.gc_input = GC(in_features = num_features, out_features = gcn_hidden1, bias = bias)\n",
    "        self.gc_hidden1 = GC(in_features = gcn_hidden1, out_features = gcn_hidden2, bias = bias)\n",
    "        self.trans_h = nn.Linear(gcn_hidden1 + num_features, gcn_hidden1, bias = bias)\n",
    "        self.trans_h1 = nn.Linear(gcn_hidden2 + num_features, gcn_hidden2, bias = bias)\n",
    "    def forward(self, features: torch.Tensor, adj: torch.sparse.FloatTensor) -> torch.Tensor:\n",
    "        hidden1 = F.relu(self.trans_h(torch.cat([self.gc_input(features, adj), features], dim=1)))\n",
    "        hidden1 = self.dropout(hidden1)\n",
    "        hidden2 = F.relu(self.trans_h1(torch.cat([self.gc_hidden1(hidden1, adj), features], dim=1)))\n",
    "        return hidden1,hidden2\n",
    "\n",
    "class HierGlobalGCN(nn.Module):\n",
    "    def __init__(self, num_features: int,\n",
    "                 dropout: float = 0.3):\n",
    "        super(HierGlobalGCN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.global_enc = GCNEncoderWithFeatures(num_features)\n",
    "\n",
    "    def forward(self,\n",
    "               Ori, Sim, Adj, return_embeddings: bool = False):\n",
    "        Ori = self.dropout(Ori)\n",
    "        Ori_h1, Ori_h2 = self.global_enc(Ori.to(torch.float32).cuda(), Adj.to(torch.float32).cuda())\n",
    "        Ori_combination = torch.cat((Ori_h1, Ori_h2),1)\n",
    "        Ori_combination = self.dropout(Ori_combination)  \n",
    "\n",
    "        Sim = self.dropout(Sim)\n",
    "        Sim_h1, Sim_h2 = self.global_enc(Sim.to(torch.float32).cuda(), Adj.to(torch.float32).cuda())\n",
    "        Sim_combination = torch.cat((Sim_h1, Sim_h2),1)\n",
    "        Sim_combination = self.dropout(Sim_combination)  \n",
    "        Fin_fea = torch.cat((Ori_combination,Sim_combination),1)\n",
    "        output = Fin_fea.mm(Fin_fea.T)\n",
    "        return  output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598173812279342\n",
      "0.9624333939196221\n",
      "0.3673469387755102\n",
      "22---------------epoch------------------22\n",
      "0.39788780354491055\n",
      "0.9435723090727729\n",
      "0.4574468085106383\n",
      "22---------------epoch------------------22\n",
      "0.2721607709006746\n",
      "0.9308813889822245\n",
      "0.3365384615384615\n",
      "22---------------epoch------------------22\n",
      "0.25521293409149987\n",
      "0.9450299456799294\n",
      "0.3387978142076503\n",
      "22---------------epoch------------------22\n",
      "0.3074865597185732\n",
      "0.952629207927872\n",
      "0.32307692307692304\n",
      "22---------------epoch------------------22\n",
      "0.32205212785876364\n",
      "0.9336729645785475\n",
      "0.37499999999999994\n",
      "22---------------epoch------------------22\n",
      "0.2780361908326095\n",
      "0.960322794700002\n",
      "0.3350785340314136\n",
      "22---------------epoch------------------22\n",
      "0.3119300115299478\n",
      "0.9517605001257501\n",
      "0.41463414634146334\n",
      "22---------------epoch------------------22\n",
      "0.36132433590838253\n",
      "0.9331478487652447\n",
      "0.18644067796610167\n",
      "22---------------epoch------------------22\n",
      "0.24579436736191101\n",
      "0.9447766127193983\n",
      "0.3014705882352941\n",
      "22---------------epoch------------------22\n",
      "0.24353618095673704\n",
      "0.9272962572655976\n",
      "0.3350785340314136\n",
      "22---------------epoch------------------22\n",
      "0.30852803649499244\n",
      "0.9523925219509605\n",
      "0.4293193717277487\n",
      "22---------------epoch------------------22\n",
      "0.2187680116639848\n",
      "0.9404281426262492\n",
      "0.2777777777777778\n",
      "22---------------epoch------------------22\n",
      "0.405854224571858\n",
      "0.9453191415272829\n",
      "0.4334600760456274\n",
      "22---------------epoch------------------22\n",
      "0.27798065011033446\n",
      "0.933432281332672\n",
      "0.36686390532544383\n",
      "22---------------epoch------------------22\n",
      "0.32258105061506437\n",
      "0.9556609132296673\n",
      "0.17821782178217824\n",
      "22---------------epoch------------------22\n",
      "0.2365029679642694\n",
      "0.9149688815926327\n",
      "0.34615384615384615\n",
      "22---------------epoch------------------22\n",
      "0.35959599552780863\n",
      "0.9570842585569693\n",
      "0.3346613545816733\n",
      "22---------------epoch------------------22\n",
      "0.3232527524724137\n",
      "0.9224164158026011\n",
      "0.4057971014492754\n",
      "22---------------epoch------------------22\n",
      "0.294176769025863\n",
      "0.9646058515756618\n",
      "0.37815126050420167\n",
      "22---------------epoch------------------22\n",
      "0.3340828950288265\n",
      "0.9756676619645172\n",
      "0.46739130434782605\n",
      "22---------------epoch------------------22\n",
      "0.23386020271753818\n",
      "0.9486039448379381\n",
      "0.20408163265306123\n",
      "22---------------epoch------------------22\n",
      "0.2679423104073186\n",
      "0.9389684092273721\n",
      "0.34285714285714286\n",
      "22---------------epoch------------------22\n",
      "0.2912006104110052\n",
      "0.932065754282823\n",
      "0.38095238095238093\n",
      "22---------------epoch------------------22\n",
      "0.3021642080335837\n",
      "0.9314747210001353\n",
      "0.36820083682008364\n",
      "22---------------epoch------------------22\n",
      "0.46020091796181184\n",
      "0.9415974692045854\n",
      "0.48\n",
      "22---------------epoch------------------22\n",
      "0.26694844204433904\n",
      "0.9451719977422546\n",
      "0.2857142857142857\n",
      "22---------------epoch------------------22\n",
      "0.3558929094363973\n",
      "0.9694473931075344\n",
      "0.3514644351464436\n",
      "22---------------epoch------------------22\n",
      "0.2610131348547425\n",
      "0.92986261282437\n",
      "0.29906542056074764\n",
      "22---------------epoch------------------22\n",
      "0.2753442114144874\n",
      "0.9466516674869342\n",
      "0.3909090909090909\n",
      "22---------------epoch------------------22\n",
      "0.34437467027709034\n",
      "0.9555623793648008\n",
      "0.3886255924170616\n",
      "22---------------epoch------------------22\n",
      "0.2775820553800536\n",
      "0.9283076430434987\n",
      "0.3493975903614458\n",
      "22---------------epoch------------------22\n",
      "0.20403156904994607\n",
      "0.9553229922340031\n",
      "0.28723404255319146\n",
      "22---------------epoch------------------22\n",
      "0.2841836503134583\n",
      "0.9550965830641162\n",
      "0.15053763440860213\n",
      "22---------------epoch------------------22\n",
      "0.28952276502043733\n",
      "0.948005908262648\n",
      "0.35028248587570626\n",
      "22---------------epoch------------------22\n",
      "0.24603263531560587\n",
      "0.9589644254051033\n",
      "0.28448275862068967\n",
      "22---------------epoch------------------22\n",
      "0.33886608018134085\n",
      "0.9659504260656397\n",
      "0.4198895027624309\n",
      "22---------------epoch------------------22\n",
      "0.25828694080639625\n",
      "0.9357312613267643\n",
      "0.36\n",
      "22---------------epoch------------------22\n",
      "0.30063714393592267\n",
      "0.9459593329563345\n",
      "0.3542857142857143\n",
      "22---------------epoch------------------22\n",
      "0.28551814847135076\n",
      "0.9236116610196905\n",
      "0.25225225225225223\n",
      "22---------------epoch------------------22\n",
      "0.34739647854454214\n",
      "0.9472695305469797\n",
      "0.37037037037037035\n",
      "22---------------epoch------------------22\n",
      "0.2657776369478374\n",
      "0.9428798082252522\n",
      "0.38532110091743116\n",
      "22---------------epoch------------------22\n",
      "0.27210421874896346\n",
      "0.9541702512397601\n",
      "0.37037037037037046\n",
      "22---------------epoch------------------22\n",
      "0.33607708974267425\n",
      "0.950197728096296\n",
      "0.3625730994152046\n",
      "22---------------epoch------------------22\n",
      "0.19457148604747135\n",
      "0.9432679371906149\n",
      "0.29000000000000004\n",
      "22---------------epoch------------------22\n",
      "0.28901163773599\n",
      "0.9245141180008217\n",
      "0.40740740740740744\n",
      "22---------------epoch------------------22\n",
      "0.3595896880447809\n",
      "0.9264839757033446\n",
      "0.38636363636363635\n",
      "22---------------epoch------------------22\n",
      "0.23412234027670292\n",
      "0.9396056808829902\n",
      "0.20689655172413793\n",
      "22---------------epoch------------------22\n",
      "0.3669084450704665\n",
      "0.9457168412982366\n",
      "0.39999999999999997\n",
      "22---------------epoch------------------22\n",
      "0.28093900048570497\n",
      "0.948679855564043\n",
      "0.3274336283185841\n",
      "22---------------epoch------------------22\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn import preprocessing  \n",
    "from sklearn.metrics import auc\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "import scipy.sparse as sp\n",
    "from torch.optim import SGD\n",
    "min_max_scaler = preprocessing.MinMaxScaler() \n",
    "loss_MSE=torch.nn.MSELoss(reduction='none')\n",
    "def normalize_adj(adj: sp.csr_matrix) -> sp.coo_matrix:\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj\n",
    "    rowsum = np.array(adj_.sum(0))\n",
    "    rowsum_power = []\n",
    "    for i in rowsum:\n",
    "        for j in i:\n",
    "            if j !=0 :\n",
    "                j_power = np.power(j, -0.5)\n",
    "                rowsum_power.append(j_power)\n",
    "            else:\n",
    "                j_power = 0\n",
    "                rowsum_power.append(j_power)\n",
    "    rowsum_power = np.array(rowsum_power)\n",
    "    degree_mat_inv_sqrt = sp.diags(rowsum_power)\n",
    "    adj_norm = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "    return adj_norm\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx) \\\n",
    "        -> torch.sparse.FloatTensor:\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "High_neighbour_number = 5\n",
    "aucss,aupr,recall,f1=[],[],[],[]\n",
    "for cross_index in range(10):\n",
    "    dicts_train_y_true,dicts_test_y_true,dict_test_list,dict_train_list,dict_train_list_only_p={},{},{},{},{}\n",
    "    for index in range(5):\n",
    "        if index not in dicts_train_y_true:\n",
    "            dicts_train_y_true[index]=np.zeros((len(drug),len(drug)))\n",
    "            dicts_test_y_true[index]=np.zeros((len(drug),len(drug)))\n",
    "            dict_test_list[index]=[]\n",
    "            dict_train_list[index]=[]\n",
    "            dict_train_list_only_p[index]=[]  #gold drug combination position in train set\n",
    "    for index_out,value_out in enumerate(drug):\n",
    "        for index_inn,value_in in enumerate(drug):\n",
    "            if index_inn > index_out:\n",
    "                temp = random.randint(0,4)\n",
    "                if value_out+'_'+value_in in Gold_dict :\n",
    "                    dicts_test_y_true[temp][index_out][index_inn]=1\n",
    "                    dict_test_list[temp].append((index_out,index_inn))\n",
    "                    dicts_test_y_true[temp][index_inn][index_out]=1\n",
    "                    dict_test_list[temp].append((index_inn,index_out))\n",
    "                else:\n",
    "                    #  if random.randint(0,29)==1:\n",
    "                    dict_test_list[temp].append((index_out,index_inn))        \n",
    "                    dict_test_list[temp].append((index_inn,index_out))\n",
    "                for index in range(5):\n",
    "                    if temp!=index:\n",
    "                        if value_out+'_'+value_in in Gold_dict :\n",
    "                            dicts_train_y_true[index][index_out][index_inn]=1\n",
    "                            dict_train_list[index].append((index_out,index_inn))\n",
    "                            dicts_train_y_true[index][index_inn][index_out]=1\n",
    "                            dict_train_list[index].append((index_inn,index_out))   \n",
    "                            dict_train_list_only_p[index].append((index_out,index_inn))\n",
    "                            dict_train_list_only_p[index].append((index_inn,index_out))             \n",
    "                        else:\n",
    "                        #    if random.randint(0,29)==1:\n",
    "                            dict_train_list[index].append((index_out,index_inn))\n",
    "                            dict_train_list[index].append((index_inn,index_out))\n",
    "    for key in dicts_train_y_true.keys():            \n",
    "        dict_train_list[key]=np.array(dict_train_list[key])                 \n",
    "        dict_test_list[key]=np.array(dict_test_list[key])\n",
    "        dicts_train_y_true[key]=torch.from_numpy(dicts_train_y_true[key]).to(device)\n",
    "        dicts_test_y_true[key]=torch.from_numpy(dicts_test_y_true[key]).to(device)\n",
    "\n",
    "    for inde in range(5):\n",
    "        model = HierGlobalGCN(num_features=180).to(device)\n",
    "        dicts_test={}\n",
    "        for i in range(len(dict_test_list[inde])):\n",
    "            dicts_test[str(dict_test_list[inde][i][0])+'_'+str(dict_test_list[inde][i][1])]=1\n",
    "        mask = dicts_train_y_true[inde].clone()\n",
    "        Weight = len(dict_train_list[inde])/sum(sum(dicts_train_y_true[inde]))\n",
    "        dicts_train={}\n",
    "        for i in range(len(dict_train_list[inde])):\n",
    "            dicts_train[str(dict_train_list[inde][i][0])+'_'+str(dict_train_list[inde][i][1])]=1\n",
    "        for i in range(drug_size):\n",
    "            for j in range(drug_size):\n",
    "                if str(i)+'_'+str(j)  not in dicts_test:\n",
    "                    if mask[i][j]==1:\n",
    "                        mask[i][j]=Weight/2#math.log2(Weight)\n",
    "                    elif str(i)+'_'+str(j) in dicts_train :\n",
    "                        mask[i][j]=1\n",
    "\n",
    "\n",
    "        optimizer = SGD(params=model.parameters(), lr=1e-6, momentum=0.9)\n",
    "        '''\n",
    "        High_neighbour\n",
    "        '''\n",
    "        combine_svd = torch.cat((X_original_svd,X_similarity_svd),dim=1)\n",
    "        combine_svd = combine_svd.to(\"cpu\").detach().numpy()\n",
    "        Sim_combine_svd = np.zeros((drug_size, drug_size))\n",
    "        for index_tem in range(drug_size):\n",
    "            for index_2_tem in range(drug_size):\n",
    "                Sim_combine_svd[index_tem][index_2_tem] = spearmanr(combine_svd[index_tem],combine_svd[index_2_tem])[0]\n",
    "        Sim_combine_svd = torch.from_numpy(Sim_combine_svd).to(\"cpu\").cuda()\n",
    "        Sim_combine_svd = Sim_combine_svd - torch.eye(drug_size).cuda()\n",
    "        fin_com_sim = torch.zeros((drug_size, drug_size))\n",
    "        for index_eye in range(drug_size):\n",
    "                fin_com_sim[index_eye]=(Sim_combine_svd[index_eye]-torch.min(torch.topk(Sim_combine_svd, High_neighbour_number, dim=1).values,dim=1).values[index_eye])\n",
    "        \n",
    "        new_dict_train_list_only_p=[]\n",
    "        for value in dict_train_list_only_p[inde]:\n",
    "            new_dict_train_list_only_p.append(value)\n",
    "        for inde_1 in range(drug_size):\n",
    "                for inde_2 in range(drug_size):\n",
    "                    if inde_2>inde_1 and fin_com_sim[inde_1][inde_2]>=0:\n",
    "                        new_dict_train_list_only_p.append((inde_2,inde_1))\n",
    "                        new_dict_train_list_only_p.append((inde_1,inde_2))\n",
    "        data_train= np.ones(len(new_dict_train_list_only_p))\n",
    "        adj = sp.csr_matrix((data_train, (np.array(new_dict_train_list_only_p)[:, 0], np.array(new_dict_train_list_only_p)[:, 1])),              \n",
    "                                shape=(drug_size, drug_size))   \n",
    "                                \n",
    "\n",
    "        adj_norm = normalize_adj(adj)         \n",
    "        adj_norm = sparse_mx_to_torch_sparse_tensor(adj_norm).cuda()\n",
    "        maxs,aucs,auprs,flag=0,0,0,0\n",
    "        for index in range(1000):\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_original_svd.to(torch.float32),X_similarity_svd.to(torch.float32).detach(),adj_norm.to(torch.float32))\n",
    "\n",
    "            dicts_train_y_true[inde]=dicts_train_y_true[inde]\n",
    "\n",
    "            loss = torch.sum(loss_MSE(y_pred.to(\"cpu\").to(torch.float32), dicts_train_y_true[inde].to(\"cpu\").to(torch.float32))* mask.to(\"cpu\"))\n",
    "            loss.to(torch.float32).backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if index %10 == 0:\n",
    "                precision, recall, pr_thresholds = precision_recall_curve(dicts_train_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])],y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], pos_label=1)\n",
    "                aupr_score = auc(recall, precision) \n",
    "                fpr, tpr, thresholds = roc_curve(dicts_train_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], pos_label=1)           \n",
    "                if np.trapz(tpr,fpr) > maxs:\n",
    "                    flag=1\n",
    "                    maxs=np.trapz(tpr,fpr)\n",
    "                precision, recall, pr_thresholds = precision_recall_curve(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])],y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], pos_label=1)\n",
    "                aupr_score = auc(recall, precision) \n",
    "                fpr, tpr, thresholds = roc_curve(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], pos_label=1)\n",
    "                if flag==1:\n",
    "                    flag=0\n",
    "                    torch.save(model, \"../model/DCGCN_model\") \n",
    "        '''\n",
    "        DCGCN test\n",
    "        '''\n",
    "        model = torch.load(\"../model/DCGCN_model\")\n",
    "        model.eval()\n",
    "        y_pred = model(X_original_svd.to(torch.float32),X_similarity_svd.to(torch.float32).detach(),adj_norm.to(torch.float32))\n",
    "\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(dicts_train_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])],y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], pos_label=1)\n",
    "        aupr_score = auc(recall, precision) \n",
    "        fpr, tpr, thresholds = roc_curve(dicts_train_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_train_list[inde][:,0]),list(dict_train_list[inde][:,1])], pos_label=1)\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])],y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], pos_label=1)\n",
    "        aupr_score = auc(recall, precision) \n",
    "        print(aupr_score)\n",
    "        aupr.append(aupr_score)\n",
    "        fpr, tpr, thresholds = roc_curve(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])], pos_label=1)\n",
    "        print(str(np.trapz(tpr,fpr)))  \n",
    "        aucss.append(np.trapz(tpr,fpr))\n",
    "        y_pred_minMax = min_max_scaler.fit_transform(y_pred.to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])].reshape(-1, 1))\n",
    "        y_pred_minMax[y_pred_minMax>0.5]=1\n",
    "        y_pred_minMax[y_pred_minMax<=0.5]=0\n",
    "        print(f1_score(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])],y_pred_minMax))\n",
    "        f1.append(f1_score(dicts_test_y_true[inde].to(\"cpu\",torch.double).detach().numpy()[list(dict_test_list[inde][:,0]),list(dict_test_list[inde][:,1])],y_pred_minMax))\n",
    "        print(\"22---------------epoch------------------22\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445328320620212\n",
      "0.2965332529017064\n",
      "0.34391344420895875\n",
      "0.013097623992782238\n",
      "0.052534480238029556\n",
      "0.07176721413212694\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(aucss)) \n",
    "print(np.mean(aupr))\n",
    "print(np.mean(f1))\n",
    "print(np.std(aucss)) \n",
    "print(np.std(aupr))\n",
    "print(np.std(f1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e6c41a7d2ff264877157aa65f3273cf4e15687dd686b8526324dab172b24bc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
